{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RQ-qWR0hFghB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ybr/Developer/ECS-174/ecs174-final-project/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import kagglehub\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p50uMhCRFghC",
    "outputId": "10079582-4816-431e-c901-e6cf2a8ea3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal images path: /Users/ybr/.cache/kagglehub/datasets/atulyakumar98/pothole-detection-dataset/versions/4/normal\n",
      "Potholes images path: /Users/ybr/.cache/kagglehub/datasets/atulyakumar98/pothole-detection-dataset/versions/4/potholes\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"atulyakumar98/pothole-detection-dataset\")\n",
    "\n",
    "normal_dir = os.path.join(path, 'normal')\n",
    "potholes_dir = os.path.join(path, 'potholes')\n",
    "print(\"Normal images path:\", normal_dir)\n",
    "print(\"Potholes images path:\", potholes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpV2Ahc0FghC",
    "outputId": "b0b13adb-a4c4-4de8-fd9e-cd5dc1779b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /Users/ybr/.cache/kagglehub/datasets/atulyakumar98/pothole-detection-dataset/versions/4\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset downloaded to:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jWAAm6hTFghC"
   },
   "outputs": [],
   "source": [
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_names = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_names[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        label = 0 if 'normal' in self.image_dir else 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kBWkTCSLFghC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "normal_dataset = PotholeDataset(image_dir=normal_dir, transform=transform)\n",
    "potholes_dataset = PotholeDataset(image_dir=potholes_dir, transform=transform)\n",
    "dataset = normal_dataset + potholes_dataset\n",
    "\n",
    "train_indices_file = 'train_indices.npy'\n",
    "test_indices_file = 'test_indices.npy'\n",
    "\n",
    "if os.path.exists(train_indices_file) and os.path.exists(test_indices_file):\n",
    "    # Load the split indices from files\n",
    "    train_indices = np.load(train_indices_file)\n",
    "    test_indices = np.load(test_indices_file)\n",
    "else:\n",
    "    # Split the dataset into training and test sets\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "\n",
    "    # Save the split indices to files\n",
    "    np.save(train_indices_file, train_indices)\n",
    "    np.save(test_indices_file, test_indices)\n",
    "\n",
    "# Create subsets using the saved indices\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for training, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# MobileNet V2\n",
    "mobilenet_v2_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "mobilenet_v2_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(mobilenet_v2_model.last_channel, 2),\n",
    ")\n",
    "mobilenet_v2_optimizer = optim.Adam(mobilenet_v2_model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# EfficientNetV2L\n",
    "efficientnetv2l_model = models.efficientnet_v2_l(weights=models.EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
    "efficientnetv2l_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(efficientnetv2l_model.classifier[1].in_features, 2),\n",
    ")\n",
    "efficientnetv2l_optimizer = optim.Adam(efficientnetv2l_model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "#ResNet50\n",
    "resnet50_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, 2)\n",
    "resnet50_optimizer = optim.Adam(resnet50_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "#ResNet101\n",
    "resnet101_model = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "resnet101_model.fc = nn.Linear(resnet101_model.fc.in_features, 2)\n",
    "resnet101_optimizer = optim.Adam(resnet101_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "#ResNet152\n",
    "resnet152_model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "resnet152_model.fc = nn.Linear(resnet152_model.fc.in_features, 2)\n",
    "resnet152_optimizer = optim.Adam(resnet152_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# VGG19\n",
    "vgg19_model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "vgg19_model.classifier[6] = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(vgg19_model.classifier[6].in_features, 2),\n",
    ")\n",
    "vgg19_optimizer = optim.Adam(vgg19_model.classifier.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaCsLQj7Lv99"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9PdRHo5AFghD"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_classification_model(name, model, optimizer, train_loader, num_epochs=10):\n",
    "    model = model.to(device)\n",
    "    saved_model_path = f\"{name}.pth\"\n",
    "    if os.path.exists(saved_model_path):\n",
    "        print(f\"Loading saved model from {saved_model_path}\")\n",
    "        model.load_state_dict(torch.load(saved_model_path, weights_only=True))\n",
    "        return\n",
    "    model.train()\n",
    "    print(f\"Training {name}...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        runningLoss = 0.0\n",
    "        correctPredictions = 0.0\n",
    "        totalPredictions = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            totalPredictions += labels.size(0)\n",
    "            correctPredictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epochLoss = runningLoss / len(train_loader)\n",
    "        epochAccuracy = (correctPredictions / totalPredictions) * 100\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epochLoss:.4f}, Accuracy: {epochAccuracy:.2f}%\")\n",
    "\n",
    "    print(f\"Finished training {name}\")\n",
    "    torch.save(model.state_dict(), saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJx-394sMuYK"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate_classification_model(model, test_loader):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    correctPredictions = 0.0\n",
    "    totalPredictions = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            totalPredictions += labels.size(0)\n",
    "            correctPredictions += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (correctPredictions / totalPredictions) * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    print(\"Time taken:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from resnet50.pth\n",
      "Loading saved model from resnet101.pth\n",
      "Loading saved model from resnet152.pth\n",
      "Loading saved model from vgg19.pth\n",
      "Loading saved model from mobilenet_v2.pth\n",
      "Loading saved model from efficientnet_v2_l.pth\n"
     ]
    }
   ],
   "source": [
    "train_classification_model(\"resnet50\", resnet50_model, resnet50_optimizer, train_loader)\n",
    "train_classification_model(\"resnet101\", resnet101_model, resnet101_optimizer, train_loader)\n",
    "train_classification_model(\"resnet152\", resnet152_model, resnet152_optimizer, train_loader)\n",
    "train_classification_model(\"vgg19\", vgg19_model, vgg19_optimizer, train_loader)\n",
    "train_classification_model(\"mobilenet_v2\", mobilenet_v2_model, mobilenet_v2_optimizer, train_loader)\n",
    "train_classification_model(\"efficientnet_v2_l\", efficientnetv2l_model, efficientnetv2l_optimizer, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.35%\n",
      "Time taken: 3.08949875831604 seconds\n",
      "Test Accuracy: 97.81%\n",
      "Time taken: 1.993407964706421 seconds\n",
      "Test Accuracy: 97.08%\n",
      "Time taken: 2.2469348907470703 seconds\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 2.1334340572357178 seconds\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 2.469303846359253 seconds\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 2.4094321727752686 seconds\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification_model(efficientnetv2l_model, test_loader)\n",
    "evaluate_classification_model(mobilenet_v2_model, test_loader)\n",
    "evaluate_classification_model(resnet101_model, test_loader)\n",
    "evaluate_classification_model(resnet50_model, test_loader)\n",
    "evaluate_classification_model(resnet152_model, test_loader)\n",
    "evaluate_classification_model(vgg19_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW8XmrARM5be",
    "outputId": "97afa814-fb79-434e-ab50-170b5fa6e0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models: resnet50_model, resnet101_model, resnet152_model\n",
      "Test Accuracy: 100.00%\n",
      "Time taken: 3.694265127182007 seconds\n",
      "Evaluating models: resnet50_model, resnet101_model, vgg19_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.4504778385162354 seconds\n",
      "Evaluating models: resnet50_model, resnet101_model, mobilenet_v2_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 2.8902969360351562 seconds\n",
      "Evaluating models: resnet50_model, resnet101_model, efficientnetv2l_model\n",
      "Test Accuracy: 98.54%\n",
      "Time taken: 3.9301140308380127 seconds\n",
      "Evaluating models: resnet50_model, resnet152_model, vgg19_model\n",
      "Test Accuracy: 100.00%\n",
      "Time taken: 3.724364995956421 seconds\n",
      "Evaluating models: resnet50_model, resnet152_model, mobilenet_v2_model\n",
      "Test Accuracy: 100.00%\n",
      "Time taken: 3.2510271072387695 seconds\n",
      "Evaluating models: resnet50_model, resnet152_model, efficientnetv2l_model\n",
      "Test Accuracy: 100.00%\n",
      "Time taken: 4.436911106109619 seconds\n",
      "Evaluating models: resnet50_model, vgg19_model, mobilenet_v2_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.035280227661133 seconds\n",
      "Evaluating models: resnet50_model, vgg19_model, efficientnetv2l_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 4.252969026565552 seconds\n",
      "Evaluating models: resnet50_model, mobilenet_v2_model, efficientnetv2l_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.487792730331421 seconds\n",
      "Evaluating models: resnet101_model, resnet152_model, vgg19_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.965696096420288 seconds\n",
      "Evaluating models: resnet101_model, resnet152_model, mobilenet_v2_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.339226007461548 seconds\n",
      "Evaluating models: resnet101_model, resnet152_model, efficientnetv2l_model\n",
      "Test Accuracy: 98.54%\n",
      "Time taken: 4.705919027328491 seconds\n",
      "Evaluating models: resnet101_model, vgg19_model, mobilenet_v2_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.419222831726074 seconds\n",
      "Evaluating models: resnet101_model, vgg19_model, efficientnetv2l_model\n",
      "Test Accuracy: 98.54%\n",
      "Time taken: 4.6644251346588135 seconds\n",
      "Evaluating models: resnet101_model, mobilenet_v2_model, efficientnetv2l_model\n",
      "Test Accuracy: 98.54%\n",
      "Time taken: 3.8619558811187744 seconds\n",
      "Evaluating models: resnet152_model, vgg19_model, mobilenet_v2_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.4524879455566406 seconds\n",
      "Evaluating models: resnet152_model, vgg19_model, efficientnetv2l_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 4.642958164215088 seconds\n",
      "Evaluating models: resnet152_model, mobilenet_v2_model, efficientnetv2l_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.983031749725342 seconds\n",
      "Evaluating models: vgg19_model, mobilenet_v2_model, efficientnetv2l_model\n",
      "Test Accuracy: 99.27%\n",
      "Time taken: 3.9945430755615234 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_three_models_at_once(model1, model2, model3, test_loader):\n",
    "    start = time.time()\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    correctPredictions = 0.0\n",
    "    totalPredictions = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs1 = model1(inputs)\n",
    "            outputs2 = model2(inputs)\n",
    "            outputs3 = model3(inputs)\n",
    "            _, predicted1 = torch.max(outputs1, 1)\n",
    "            _, predicted2 = torch.max(outputs2, 1)\n",
    "            _, predicted3 = torch.max(outputs3, 1)\n",
    "            \n",
    "            # Majority vote\n",
    "            for i in range(labels.size(0)):\n",
    "                votes = [predicted1[i].item(), predicted2[i].item(), predicted3[i].item()]\n",
    "                final_prediction = max(set(votes), key=votes.count)\n",
    "                if final_prediction == labels[i].item():\n",
    "                    correctPredictions += 1\n",
    "            totalPredictions += labels.size(0)\n",
    "\n",
    "    accuracy = (correctPredictions / totalPredictions) * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    end = time.time()\n",
    "    print(\"Time taken:\", end - start, \"seconds\")\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "# List of models\n",
    "models = [resnet50_model, resnet101_model, resnet152_model, vgg19_model, mobilenet_v2_model, efficientnetv2l_model]\n",
    "models = {\n",
    "    'resnet50_model': resnet50_model,\n",
    "    'resnet101_model': resnet101_model,\n",
    "    'resnet152_model': resnet152_model,\n",
    "    'vgg19_model': vgg19_model,\n",
    "    'mobilenet_v2_model': mobilenet_v2_model,\n",
    "    'efficientnetv2l_model': efficientnetv2l_model\n",
    "}\n",
    "\n",
    "# Go through each possible combination of the models\n",
    "for model1_name, model2_name, model3_name in itertools.combinations(models.keys(), 3):\n",
    "    model1 = models[model1_name]\n",
    "    model2 = models[model2_name]\n",
    "    model3 = models[model3_name]\n",
    "    print(f\"Evaluating models: {model1_name}, {model2_name}, {model3_name}\")\n",
    "    evaluate_three_models_at_once(model1, model2, model3, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
